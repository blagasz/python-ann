{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import neurolab as nl\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create train samples\n",
      "x = np.linspace(-7, 7, 20)\n",
      "y = np.sin(x) * 0.5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "size = len(x)\n",
      "\n",
      "inp = x.reshape(size,1)\n",
      "tar = y.reshape(size,1)\n",
      "\n",
      "# Create network with 2 layers and random initialized\n",
      "net = nl.net.newff([[-7, 7]],[5, 1])\n",
      "\n",
      "# Train network\n",
      "# default train method is\n",
      "# BroydenFletcherGoldfarbShanno (BFGS) method Using scipy.optimize.fmin_bfgs\n",
      "error = net.train(inp, tar, epochs=500, show=100, goal=0.02)\n",
      "\n",
      "# Simulate network\n",
      "out = net.sim(inp)\n",
      "\n",
      "# Plot result\n",
      "import pylab as pl\n",
      "pl.subplot(211)\n",
      "pl.plot(error)\n",
      "pl.xlabel('Epoch number')\n",
      "pl.ylabel('error (default SSE)')\n",
      "\n",
      "x2 = np.linspace(-6.0,6.0,150)\n",
      "y2 = net.sim(x2.reshape(x2.size,1)).reshape(x2.size)\n",
      "\n",
      "y3 = out.reshape(size)\n",
      "\n",
      "pl.subplot(212)\n",
      "pl.plot(x2, y2, '-',x , y, '.', x, y3, 'p')\n",
      "pl.legend(['train target', 'net output'])\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}